# Demo: Integraci√≥n de Modelos LLM con SDK de OpenAI (TypeScript)

Este repositorio contiene programas de consola creados en TypeScript para ejemplificar c√≥mo se integra y utiliza un modelo de Lenguaje Grande (LLM) mediante el SDK oficial de OpenAI. Estos ejemplos est√°n dise√±ados para fines educativos, demostrando conceptos clave en la interacci√≥n con LLMs y la ingenier√≠a de *prompts*.

## ‚öôÔ∏è Requisitos Previos

1. **Node.js** (v14 o superior)
2. **Clave de API de OpenAI**: Necesitas una clave v√°lida (`API Key`) de OpenAI. Si no tienes una, puedes generarla en la [plataforma de desarrolladores de OpenAI](https://platform.openai.com/).

## üöÄ Instalaci√≥n y Configuraci√≥n

1. Instala las dependencias del proyecto ejecutando:
   ```bash
   npm install
   ```

2. Configura las variables de entorno:
   - Copia el archivo de ejemplo o ren√≥mbralo:
     ```bash
     cp .env.example .env
     ```
   - Abre el archivo `.env` y reemplaza el valor de `OPENAI_API_KEY` con tu clave real de OpenAI.
   > **Importante:** Nunca subas tu archivo `.env` o tu API Key real al repositorio. Aseg√∫rate de que este archivo est√© incluido en tu `.gitignore`.

---

## üìö Ejemplos Incluidos

### 1. El Impacto del System Prompt (`ejemplo1.ts`)

Este ejemplo demuestra c√≥mo la instrucci√≥n principal o "directiva del sistema" (`System Prompt`) afecta dr√°sticamente el comportamiento y el tono del modelo frente a un mismo est√≠mulo del usuario (`User Prompt`).

- **¬øQu√© hace?** Le pide al usuario una pregunta (ej. "¬øPor qu√© el cielo es azul?") y env√≠a esta misma pregunta al modelo utilizando dos personalidades completamente distintas: un pirata gru√±√≥n y un maestro de primaria paciente.
- **Conceptos clave:** `System Prompt`, `User Prompt`, Personalidad/Rol del Agente (Role-playing).
- **C√≥mo ejecutarlo:**
  ```bash
  npm run ejemplo1
  ```

### 2. Anatom√≠a T√©cnica de un Prompt de Ingenier√≠a (`ejemplo2.ts`)

Para que un texto enviado a un LLM pase de ser una simple pregunta a una pieza de ingenier√≠a estructurada, debe estar correctamente parametrizado. Este ejemplo simula un clasificador de tickets de soporte t√©cnico para ilustrar este concepto.

- **¬øQu√© hace?** Ensambla un *prompt* maestro combinando varios componentes clave y luego le pide al usuario un caso de soporte ("El teclado de mi laptop no funciona"). El modelo eval√∫a el caso y devuelve un JSON debidamente formateado con la clasificaci√≥n.
- **Componentes demostrados:**
  1. **Instrucci√≥n (Misi√≥n):** La tarea espec√≠fica (ej: Clasificar el ticket y asignar urgencia).
  2. **Contexto (Memoria de Trabajo):** El diccionario de categor√≠as v√°lidas para el soporte.
  3. **Restricciones (Guardrails):** L√≠mites r√≠gidos (ej. "Solo responde en formato JSON", "No asumas datos sensibles").
  4. **Ejemplos (Few-shot):** Muestras de qu√© entra y qu√© debe salir para reducir la varianza en las respuestas.
  5. **Datos de Entrada (Input):** La variable del usuario a procesar.
- **Conceptos clave:** Ingenier√≠a de Prompts (Prompt Engineering), Few-shot prompting, Guardrails, Control de Temperatura (`temperature: 0.1` para tareas deterministas), Salidas estructuradas (JSON).
- **C√≥mo ejecutarlo:**
  ```bash
  npm run ejemplo2
  ```

---

*Nota: Los ejemplos utilizan el modelo `gpt-3.5-turbo` por defecto por su equilibrio entre coste y rendimiento para estas demostraciones. Para tareas de producci√≥n m√°s complejas, se recomienda evaluar `gpt-4` o modelos m√°s recientes.*
